# Mathematical Methods for Biology Part 2: Algorithms

This is the course notes for Mathematical Methods for Biology Part 2 (BIOS 26211), a continuation of Mathematical Methods for Biology Part 1 (BIOS 26210). The first part is focused on dynamic models such as difference equations and differential equations, applied to biological questions. To implement them, students learned to use Python and Jupyter notebooks, in particular numpy arrays, loops for numerical solutions of ODEs, plotting of solutions over time and in the phase plane.

The aim of the second part of the course sequence is to introduce common computational algorithms that are used in biological sciences, while providing essential mathematical concepts to understand and implement the algorithms. These are motley crew of computational algorithms, some focused on extracting information from data, others leaning on stochastic modeling of biological phenomena. Nine algorithms will be presented:

1. Linear regression and least squares fitting
2. Gradient optimization: Gradient descent, Newton-Raphson, Levenberg-Marquardt
3. Dimensionality reduction: Principal component analysis
4. Frequency spectrum: Fast Fourier Transform
5. Data processing and filtering: Convolution
6. Sequence alignment: Needleman-Wunsch and Smith-Waterman
7. Stochastic optimization: Metropolis Monte Carlo
8. Sampling from multivariate distributions: Markov Chain Monte Carlo and Gibbs sampling
9. Stochastic simulation of reactions: Gillespie algorithm


Some of these algorithms (linear regression, gradient descent) are used in machine learning applications, such as neural networks, while others (Gillespie agorithm) provide important tools for stochastic simulation.
